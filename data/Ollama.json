{
  "models": {
    "deepseek-r1": {
      "name": "deepseek-r1",
      "tags": ["1.5b", "7b", "8b", "14b", "32b", "70b"],
      "description": "DeepSeek-R1 is a reasoning model with exceptional performance in math, code, and logical reasoning",
      "default_tag": "7b",
      "enabled": true
    },
    "deepseek-v3": {
      "name": "deepseek-v3",
      "tags": ["latest"],
      "description": "DeepSeek-V3 is a large Mixture-of-Experts (MoE) language model with 671B total parameters",
      "default_tag": "latest",
      "enabled": true
    },
    "gemma2": {
      "name": "gemma2",
      "tags": ["2b", "9b", "27b"],
      "description": "Google Gemma 2 models with improved performance and efficiency",
      "default_tag": "9b",
      "enabled": true
    },
    "llama3.2": {
      "name": "llama3.2",
      "tags": ["1b", "3b"],
      "description": "Meta's Llama 3.2 compact models optimized for edge deployment",
      "default_tag": "3b",
      "enabled": true
    },
    "llama3.1": {
      "name": "llama3.1",
      "tags": ["8b", "70b", "405b"],
      "description": "Meta's Llama 3.1 models with enhanced multilingual capabilities",
      "default_tag": "8b",
      "enabled": true
    },
    "qwen2.5": {
      "name": "qwen2.5",
      "tags": ["0.5b", "1.5b", "3b", "7b", "14b", "32b", "72b"],
      "description": "Alibaba's Qwen 2.5 models with strong multilingual support",
      "default_tag": "7b",
      "enabled": true
    },
    "phi3": {
      "name": "phi3",
      "tags": ["mini", "medium"],
      "description": "Microsoft Phi-3 compact models optimized for efficiency",
      "default_tag": "mini",
      "enabled": true
    },
    "mistral": {
      "name": "mistral",
      "tags": ["7b"],
      "description": "Mistral AI's efficient 7B parameter model",
      "default_tag": "7b",
      "enabled": true
    },
    "mixtral": {
      "name": "mixtral",
      "tags": ["8x7b", "8x22b"],
      "description": "Mistral AI's Mixture of Experts models",
      "default_tag": "8x7b",
      "enabled": true
    },
    "codellama": {
      "name": "codellama",
      "tags": ["7b", "13b", "34b", "70b"],
      "description": "Meta's Code Llama models specialized for programming tasks",
      "default_tag": "7b",
      "enabled": true
    },
    "nomic-embed-text": {
      "name": "nomic-embed-text",
      "tags": ["latest"],
      "description": "High-quality text embedding model for semantic search and RAG applications",
      "default_tag": "latest",
      "enabled": true
    },
    "mxbai-embed-large": {
      "name": "mxbai-embed-large",
      "tags": ["latest"],
      "description": "Large embedding model optimized for retrieval tasks",
      "default_tag": "latest",
      "enabled": true
    },
    "all-minilm": {
      "name": "all-minilm",
      "tags": ["l6-v2"],
      "description": "Compact sentence transformer for efficient embeddings",
      "default_tag": "l6-v2",
      "enabled": true
    }
  },
  "settings": {
    "ollama_install_command": "curl -fsSL https://ollama.com/install.sh | sh",
    "download_all_tags": false,
    "check_for_updates": true,
    "parallel_downloads": false,
    "storage_path_suffix": "ai_models"
  }
}
